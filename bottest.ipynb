{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnusnath447/BYOB/blob/main/bottest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch python-docx scipy"
      ],
      "metadata": {
        "id": "32-LnpvRbcX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from docx import Document\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Function to extract text from a .docx file, including tables\n",
        "def extract_text_from_docx(file_path):\n",
        "    doc = Document(file_path)\n",
        "    data_rows = []\n",
        "\n",
        "    # Extract text from tables\n",
        "    for table in doc.tables:\n",
        "        for row in table.rows:\n",
        "            row_text = [cell.text.strip() for cell in row.cells if cell.text.strip()]\n",
        "            if row_text:\n",
        "                data_rows.append(\" | \".join(row_text))  # Store rows as strings\n",
        "\n",
        "    return data_rows\n",
        "\n",
        "# Read document and extract rows\n",
        "file_path = \"alerts.docx\"\n",
        "table_rows = extract_text_from_docx(file_path)\n",
        "\n",
        "# Function to get embedding\n",
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()  # Mean pooling\n",
        "    return embedding\n",
        "\n",
        "# Embed each table row\n",
        "row_embeddings = {row: get_embedding(row) for row in table_rows}\n",
        "\n",
        "# Embed the query \"High CPU Usage\"\n",
        "query_text = \"Database Connection Fail\"\n",
        "query_embedding = get_embedding(query_text)\n",
        "\n",
        "# Find the most similar row using cosine similarity\n",
        "best_match = min(row_embeddings.items(), key=lambda x: cosine(query_embedding, x[1]))\n",
        "\n",
        "# Print the most relevant row\n",
        "# print(\"Best match for 'Disk Space Low':\")\n",
        "# print(best_match[0])\n"
      ],
      "metadata": {
        "id": "1VgEkHRc7rtL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def format_resolution_steps(text):\n",
        "    # Extract only the resolution steps part\n",
        "    if \"|\" in text:\n",
        "        resolution_part = text.split(\"|\")[-1].strip()  # Get the last part after '|'\n",
        "    else:\n",
        "        resolution_part = text.strip()\n",
        "\n",
        "    # Split steps using numbers like \"1.\", \"2.\", etc.\n",
        "    steps = re.split(r'\\d+\\.\\s*', resolution_part)\n",
        "    steps = [step.strip() for step in steps if step.strip()]  # Remove empty elements\n",
        "\n",
        "    # Format output\n",
        "    formatted_output = \"Resolution steps:\\n\"\n",
        "    for i, step in enumerate(steps, start=1):\n",
        "        formatted_output += f\"Step {i}: {step}\\n\"\n",
        "\n",
        "    return formatted_output.strip()\n",
        "\n",
        "# Example output from retrieval\n",
        "retrieved_text = best_match[0]\n",
        "\n",
        "# Format the retrieved output\n",
        "formatted_result = format_resolution_steps(retrieved_text)\n",
        "print(formatted_result)\n"
      ],
      "metadata": {
        "id": "bnMRgQRm9rSE",
        "outputId": "8bd853df-3afb-4c93-8c70-ae858a489936",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolution steps:\n",
            "Step 1: Verify database availability.\n",
            "Step 2: Check network connectivity.\n",
            "Step 3: Restart database service if needed.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}